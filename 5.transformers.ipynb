{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a624f183",
   "metadata": {},
   "source": [
    "### 트랜스포머의 잠재적 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d13276",
   "metadata": {},
   "source": [
    "규모가 매우 크다\n",
    "- 갈력한 모델을 학습시키는데, 많은 비용이 들어간다. 이런 비용을 충당할 수 없는 기관은 연구 범위가 제한될 수 밖에 없다.\n",
    "- 대량의 저력소모로 환경적 문제가 있다.\n",
    "- 오픈소스로 모델이 제공되어도 추론 하는데에만 많은 gpu가 필요할 수 있다.\n",
    "\n",
    "순차 처리\n",
    "- 결국 첫 토큰 부터 마지막 토큰까지 순서대로 처리하는 것이기 때문에, 순차 처리로 인해 입력 길이에 대해 2차 시간 복잡도를 가지는 문제가 있다.\n",
    "- 이는 처리 시간이 입력 길이의 제고벵 비례해 증가한다.\n",
    "\n",
    "고정 입력 크기\n",
    "- 모델이 처리 할 수 있는 최대 토큰 수가 정해져 있다. 이는 모델 규모에 따라 정해져 있어, 추후 늘리거나 할 수 없다.\n",
    "- 모델이 처리 할 수 있는 토큰의 수는 컨텐스트 윈도우 에 따라 다르다.\n",
    "\n",
    "이해하기 어려움\n",
    "- 트랜스포머는 블랙박스다. 입력에 어떤 조작을 가해서 출력으로 내뱉는지 완벽하게 알지 못한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d4248",
   "metadata": {},
   "source": [
    "### 활용 범위 - VIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bb7230",
   "metadata": {},
   "source": [
    "- 최근 다양한 분야에 트랜스포머 기법이 활용되고 있다. 특히 이미지 분야에서의 활용성도 뛰어나다. 이미지 인식부터, 분할, 객체 감지, 비디오 이해 등 여러 분야에 활용되고 있다.\n",
    "- 비전 트랜스포머 (vision transformer *VIT)의 도입으로 어텐션과 트랜스포머 기반 기술을 사용해 비전 문제를 해결해 나가고 있지만 CNN(convolutional neural network)를 완전히 배제하지는 않는다.\n",
    "- 이미지 처리 파이프라인에서 합성곱 신경망은 높은 수준의 엣지, 텍스터 및 기타 패턴을 감지하는 feature map을 추출한다. 이는 겹치지 않는 고정 크기의 patch로 나뉘고 이는 토큰 시퀀스와 유사하다.\n",
    "- 트랜스포머는 이 feature map patch간의 관계를 학습할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14524496",
   "metadata": {},
   "source": [
    "\n",
    "- VIT는 CNN보다 학습에 매우 많은 데이터를 필요로 한다. 예로, DeiT(data-efficient image transformer) 모델은 CNN에서 일반적으로 사용되는 augmentation(증강)과 regularization(정규화) 기법을 활용해 학습을 진행했다.\n",
    "- 제로샷 이미지 분류는 트랜스포머 기반 이미지 모델의 대표적인 예다. 기존의 이미지 분류 모델은 고정된 클래스 집합으로 학습되지만, 제로샷 이미지 분류는 추론 시점에 클래스를 지정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a42fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 뭐 어디서든 불러오기\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import os\n",
    "\n",
    "cache_dir = r\"D:\\WorkSpace\\Hands_on_Gen_AI\"\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "# model_id = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "# tok = AutoTokenizer.from_pretrained(model_id, cache_dir=cache_dir)\n",
    "# mdl = AutoModelForSequenceClassification.from_pretrained(model_id, cache_dir=cache_dir)\n",
    "\n",
    "# classifier = pipeline(\"text-classification\", model=mdl, tokenizer=tok)\n",
    "# print(classifier(\"I absolutely love this movie!\"))\n",
    "\n",
    "image = \"load some image\"\n",
    "\n",
    "pipe = pipeline(\"zerp-shot-image-classification\", model = \"openai/clip-vit-base-patch32\")\n",
    "labels = ['cat','dog','zebra','rion']\n",
    "pipe(image, cadidate_labels=labels )\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06576ddf",
   "metadata": {},
   "source": [
    "### 연습문제 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97618ee",
   "metadata": {},
   "source": [
    "- 지금까지 사용했던 모듈을 직접 구현 해본다.\n",
    "model.generate() 를 사용하지 않고 직접 시퀀스를 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68ccea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "prompt = \"It was a dark and stormy\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
    "Qwen2 = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d5246f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_length = input_ids.size(1)\n",
    "current_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31a027ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[ 9.0283,  6.4773,  3.8585,  ..., -4.3873, -4.3869, -4.3874],\n",
       "         [ 5.0396,  5.2072,  1.8779,  ..., -5.4419, -5.4425, -5.4426],\n",
       "         [ 2.7506,  4.8974, -0.5766,  ..., -5.5188, -5.5188, -5.5189],\n",
       "         ...,\n",
       "         [ 4.2731,  5.7324, -0.9108,  ..., -5.5750, -5.5747, -5.5756],\n",
       "         [ 4.7102,  3.7237, -0.0393,  ..., -5.8334, -5.8342, -5.8342],\n",
       "         [ 3.5512,  4.9842, -1.4630,  ..., -7.0129, -7.0131, -7.0135]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = Qwen2(input_ids)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0e4713f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 151936])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9ae91",
   "metadata": {},
   "source": [
    "- 출력의 첫 번째 차원은 배치 크기를 나타내고 우리는 한 문장만 전달 했기에 그 크기는 1입니다.\n",
    "- 두 번째 차원은 문장의 길이, 입력 문장의 토큰 수를 나타냅니다. 토크나이저마다 문장을 slice하는 기준이 다르기에 그 값은 같은 문장이라도 조금씩 다를 수 있습니다.\n",
    "- 세 번째 차원은 어휘 사전 크기를 나타냅니다.\n",
    "- 이러한 값들은 어휘 사전의 토큰에 대응하는 모델의 초기 출력 값인 logit으로 [0.1, -2.1, 1.2, 0.01 ...] 같은 숫자 리스트입니다. 이 logit을 사용해 다음 이어질 확률이 가장 높은 토큰을 선택할 수 있고 logit을 확률로 변환하는 방법도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3dab85ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 151936])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits[:, -1, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a14da4",
   "metadata": {},
   "source": [
    "outputs.logits의 형태는 보통 (batch_size, seq_len, vocab_size)입니다. 각 시퀀스의 각 위치에서 다음 토큰에 대한 점수(로짓, 정규화 전 점수)를 제공합니다.\n",
    "\n",
    "따라서 outputs.logits[:, -1, :]은 마지막 입력 토큰까지를 조건으로 했을 때 다음에 올 토큰(시퀀스의 seq_len번째 위치)에 대한 전체 어휘(vocab) 로짓 분포이며, 텐서 형태는 (batch_size, vocab_size)입니다.\n",
    "\n",
    "이 로짓에 softmax(dim=-1)를 적용하면 다음 토큰 확률 분포가 되고, argmax(dim=-1)로는 그리디하게 다음 토큰 인덱스를 선택할 수 있습니다.\n",
    "\n",
    "더 정확히 (인과적 LM에서) 위치 t의 출력은 다음을 예측합니다:\n",
    "$$𝑝(𝑥𝑡+1∣𝑥≤𝑡)$$\n",
    "\n",
    "그래서 학습 시에는 logits[:, :-1, :]와 labels[:, 1:]를 맞춰(레이블을 오른쪽으로 한 칸 시프트) 손실을 계산합니다.\n",
    "\n",
    "캐시(past_key_values) 사용 여부와 무관하게, 마지막 시퀀스 위치의 로짓을 고르면 현재 프롬프트 뒤에 올 다음 토큰의 분포를 보게 됩니다.\n",
    "\n",
    "어휘는 단어가 아니라 토크나이저(BPE/SentencePiece 등)의 토큰 단위이며, 특수 토큰(EOS 등)도 포함될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "749d6b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[17.3635, 14.3368, 13.6628, 12.1578, 12.0783, 11.5770, 11.4987, 11.2027,\n",
      "         11.1147, 11.0757]], grad_fn=<TopkBackward0>)\n",
      "tensor([[ 3729, 11458,  1899,  6556, 12406, 13354,  7728,  7270,  6602,  6527]])\n"
     ]
    }
   ],
   "source": [
    "next_token_logits = outputs.logits[:, -1, :]\n",
    "top_k_logits, _ = torch.topk(next_token_logits, 10)\n",
    "print(top_k_logits) # 어휘 사전 토큰 점수\n",
    "print(_) # 어휘 사전 토큰 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae036759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11.0757]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_top_k_value = top_k_logits[:, -1].unsqueeze(-1)\n",
    "min_top_k_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6f14698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits = torch.where(\n",
    "    next_token_logits < min_top_k_value,\n",
    "    torch.tensor(float(\"-inf\")),\n",
    "    next_token_logits,\n",
    ")\n",
    "probs = F.softmax(next_token_logits, dim=-1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d080405f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3729]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_id = torch.multinomial(probs, num_samples=1)\n",
    "next_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b13aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "prompt = \"It was a dark and stormy\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
    "Qwen2 = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "def generate(model, tokenizer, input_ids, max_length=50, do_sample=False,top_k = None):\n",
    "    '''\n",
    "    Args:\n",
    "        model : 생성에 사용할 모델, \n",
    "        tokenaizer : 생성에 사용할 토크나이저, \n",
    "        input_ids : 입력 ID, \n",
    "        max_length=50 : 시퀀스 최대 길이, \n",
    "        do_sample=False : 샘플링 사용 여부,\n",
    "        top_k = None : 샘플링할 토큰 수\n",
    "    '''\n",
    "    current_length = input_ids.size(1)  # 현재 입력된 input token 의 길이 확인\n",
    "\n",
    "    for _ in range(max_length - current_length): # 최대 시퀀스 길이에서 이미 입력된 길이 만큼 빼고 진행\n",
    "        # 모델에 입력 시퀀스 입력\n",
    "        outputs = model(input_ids)\n",
    "\n",
    "        # 현재 입력 다음에 올 토큰에 대한 vocab 전체의 로짓(점수) 목록 (batch_size, vocab_size)\n",
    "        next_token_logits = outputs.logits[:, -1, :]\n",
    "\n",
    "        if do_sample:\n",
    "            if top_k > 0:\n",
    "                # 상위 top_k 개 샘플링\n",
    "                # 상위 top_k개의 다음 토큰 점수와 토큰 ID 목록\n",
    "                top_k_logits, _ = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "                # top_k 개 중 가장  점수가 낮은 토큰\n",
    "                min_top_k_value = top_k_logits[:, -1].unsqueeze(-1)\n",
    "\n",
    "                # 상위 top_k개 중 가장 낮은 토큰 보다 점수가 낮은 토큰은 -inf 로 마스킹.\n",
    "                next_token_logits = torch.where(\n",
    "                    next_token_logits < min_top_k_value,\n",
    "                    torch.tensor(float(\"-inf\")),\n",
    "                    next_token_logits,\n",
    "                )\n",
    "\n",
    "            # softmax 적용해서 확률로 변환\n",
    "            probs = F.softmax(next_token_logits, dim=-1)\n",
    "            # 각 토큰 별 확률 기반 샘플링\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            # 가장 점수가 높은 토큰 뽑기\n",
    "            next_token_id = torch.argmax(\n",
    "                next_token_logits, dim=-1, keepdim=True\n",
    "            )\n",
    "\n",
    "        # 입력 시퀀스에 다음 예측 토큰 이어 붙이기\n",
    "        input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n",
    "\n",
    "        # 문장 끝 토큰 ID가 나오면 중단\n",
    "        if next_token_id == tokenizer.eos_token_id:\n",
    "            break\n",
    "    # 토크나이저 디코딩으로 합쳐진 시퀀스 출력\n",
    "    return tokenizer.decode(input_ids.squeeze(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a5adc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was a dark and stormy night. It was the end of a long, hard day, and it was the first in a long week of being a mother and a writer. I had come home from a long, hard day at work. It wasn’t really a hard day at work.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model = Qwen2, tokenizer = tokenizer,  input_ids = input_ids,max_length=60, do_sample=True, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd8318",
   "metadata": {},
   "source": [
    "### 연습문제 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7458231",
   "metadata": {},
   "source": [
    "1. **텍스트 생성에서 어텐션 메커니즘의 역할은 무엇인가요?**\n",
    "\n",
    "   어텐션 메커니즘은 출력 시퀀스의 각 토큰을 생성할 때 입력 시퀀스의 서로 다른 부분에 **선택적으로 집중**할 수 있게 해 줍니다. 이를 통해 단어들 사이의 **장거리 의존성**과 관계를 더 잘 포착합니다.\n",
    "\n",
    "2. **어떤 경우에 문자 기반 토크나이저(character-based tokenizer)를 선호하나요?**\n",
    "\n",
    "   문자, 기호, 이모지처럼 **개별 문자 자체가 의미를 가지는** 언어/도메인에서 유리합니다. 예를 들어 중국어는 한 글자에 담긴 정보량이 라틴 문자 언어의 한 글자보다 많은 편입니다.\n",
    "\n",
    "3. **모델이 사용한 것과 다른 토크나이저를 쓰면 어떻게 되나요?**\n",
    "\n",
    "   토크나이저가 다르면 **토크나이즈 불일치**가 발생해 토큰 경계가 어긋납니다. 그 결과 모델 입력/출력이 뒤틀려 **예상치 못한 결과**가 나올 수 있습니다.\n",
    "\n",
    "4. **생성 시 `no_repeat_ngram_size`를 사용하면 어떤 위험이 있나요? (힌트: 도시 이름을 떠올려 보세요.)**\n",
    "\n",
    "   예를 들어 `no_repeat_ngram_size=3`이면 **동일한 3-그램**은 한 번만 등장할 수 있습니다. 따라서 `\"New York City\"`라는 3-그램은 **한 번만** 생성됩니다. 뉴욕을 배경으로 이야기를 생성한다면 이런 제약은 **품질을 심각하게 떨어뜨릴** 수 있습니다.\n",
    "\n",
    "5. **빔 서치(Beam Search)와 샘플링을 함께 쓰면 어떻게 되나요?**\n",
    "\n",
    "   빔 서치는 매 시점마다 점수가 높은 **상위 k개 시퀀스(빔)**를 유지합니다. 여기에 **확률적 요소(샘플링)**를 더해, 점수 상위 후보에서 확률적으로 다음 토큰을 뽑습니다.\n",
    "   이렇게 하면 빔 서치의 **반복성**을 줄이고, 순수 샘플링의 **예측 불가능성**을 완화해 **다양성과 품질의 균형**을 얻을 수 있습니다. 다만 유지·샘플링해야 하는 시퀀스가 늘어 **계산 비용**이 커질 수 있습니다.\n",
    "\n",
    "6. **샘플링으로 코드 에디터에서 코드를 생성하는 LLM을 쓴다고 합시다. 낮은 온도(temperature)와 높은 온도 중 무엇이 더 편리할까요?**\n",
    "\n",
    "   일반적으로 **낮은 온도**가 더 편리합니다. 더 **결정론적이고 보수적인** 코드를 만들어 관용구를 잘 따르고 오류 위험을 줄입니다. 반대로 높은 온도는 무작위성이 커져 **비정형적이거나 덜 신뢰할 수 있는** 코드가 나올 수 있습니다.\n",
    "\n",
    "7. **파인튜닝의 중요성과, 제로샷(Zero-shot) 생성과의 차이는 무엇인가요?**\n",
    "\n",
    "   파인튜닝은 사전학습된 언어 모델을 **특정 작업/도메인에 맞게 적응**시키는 과정으로, 작업 고유의 뉘앙스를 학습해 **목표 성능을 끌어올립니다**. 반면 제로샷 생성은 **작업별 추가 학습 없이** 바로 모델을 사용하는 것입니다.\n",
    "\n",
    "8. **인코더(Encoder), 디코더(Decoder), 인코더-디코더(Encoder-Decoder) 트랜스포머의 차이와 활용을 설명하세요.**\n",
    "\n",
    "   * **인코더:** 입력 시퀀스를 처리해 **의미 표현**을 추출. 분류, 감성 분석, 문서 임베딩 등에 사용. 예: **BERT, RoBERTa**\n",
    "   * **디코더:** 주어진 조건을 바탕으로 **출력 시퀀스를 생성**. 텍스트 생성에 사용. 예: **GPT-2, (디코더로 동작하는) T5**\n",
    "   * **인코더-디코더:** 인코더가 입력을 표현으로 바꾸고, 디코더가 이를 이용해 출력을 생성하는 **시퀀스-투-시퀀스** 구조. 기계 번역, 요약, 질의응답 등에 적합. 예: **BART, T5**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead5536",
   "metadata": {},
   "source": [
    "### 연습문제 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d5463",
   "metadata": {},
   "source": [
    "1. 요약하기 : 요약 모델을 사용해 단락의 요약을 생성해보자.\n",
    "2. 감성 분석 : 제로샷 분류의 성능 측정 결과와 비교해 보자. 감성 분석을 할 수 있는 distibert-base-uncased-finetuned-sst-2-english  인코더 모델을 사용해보자\n",
    "3. 의미 기반 검색 : FAQ 시스템을 만들어 보자. 문장 트랜스포머는 텍스트의 의미적 유사성을 측정할 수 있는 대표적인 모델이다. 트랜스포머 인코더는 일반적으로 각 토큰에 대한 임베딩을 출력하지만 문장 트랜스포머는 전체 입력 텍스트에 대한 임베딩을 출력하여 두 텍스트의 의미가 유사한지 유사도 점수를 기반으로 판단할 수 있다. sentence_transformers 라이브러리를 사용한 간단한 에시를 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb831b9",
   "metadata": {},
   "source": [
    "#### 1. 요약하기 - 3.Transformer_block.ipynb 파일의 요약하기 자체 실습 코드 발췌\n",
    "\n",
    "2) 요약 (문서 → 요약 텍스트)\n",
    "\n",
    "**목표**: 입력을 이해하고 간결하게 재생성\n",
    "\n",
    "* **모델(권장 순)**\n",
    "\n",
    "  * 경량/속도: `google/mt5-base` (다중언어(멀티링구얼)), `google/flan-t5-base`\n",
    "  * 더 높은 질: `google/flan-t5-large` (VRAM 16GB 이상 권장)\n",
    "* **튜닝**: **LoRA** 혹은 **사전학습된 T5를 프롬프트만으로 사용** (few-shot)\n",
    "* **인퍼런스 설정**: `num_beams=4`, `no_repeat_ngram_size=3`, `max_new_tokens` 적절 조절\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import os\n",
    "cache_dir = r\"D:\\WorkSpace\\Hands_on_Gen_AI\"\n",
    "model_id = \"google/flan-t5-base\"  # 또는 \"google/mt5-base\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_id, cache_dir=cache_dir)\n",
    "mdl = AutoModelForSeq2SeqLM.from_pretrained(model_id, cache_dir=cache_dir)\n",
    "summarizer = pipeline(\"summarization\", model=mdl, tokenizer=tok)\n",
    "\n",
    "text = \"긴 문서를 여기에 넣으세요...\"\n",
    "print(summarizer(text, max_length=160, min_length=60, do_sample=False))\n",
    "```\n",
    "\n",
    "**언제 이 조합?** 비용/지연을 아끼면서 요약 품질이 필요할 때. LLM(디코더형)보다 가볍고 안정적.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "975e3673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'The number of engineering graduates in the United States has declined dramatically over the past few years, but the number of graduates in traditional engineering disciplines has remained the same in most of the top American universities. China and India, as well as other industrial countries in Europe and Asia, continue to encourage and advance the teaching of engineering. At minimum, America suffers an increasingly serious decline in the number'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import os\n",
    "cache_dir = r\"D:\\WorkSpace\\Hands_on_Gen_AI\"\n",
    "model_id = \"google/flan-t5-base\"  # 또는 \"google/mt5-base\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_id, cache_dir=cache_dir)\n",
    "mdl = AutoModelForSeq2SeqLM.from_pretrained(model_id, cache_dir=cache_dir)\n",
    "summarizer = pipeline(\"summarization\", model=mdl, tokenizer=tok)\n",
    "\n",
    "text =  \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of\n",
    "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
    "    the premier American universities engineering curricula now concentrate on\n",
    "    and encourage largely the study of engineering science. As a result, there\n",
    "    are declining offerings in engineering subjects dealing with infrastructure,\n",
    "    the environment, and related issues, and greater concentration on high\n",
    "    technology subjects, largely supporting increasingly complex scientific\n",
    "    developments. While the latter is important, it should not be at the expense\n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other\n",
    "    industrial countries in Europe and Asia, continue to encourage and advance\n",
    "    the teaching of engineering. Both China and India, respectively, graduate\n",
    "    six and eight times as many traditional engineers as does the United States.\n",
    "    Other industrial countries at minimum maintain their output, while America\n",
    "    suffers an increasingly serious decline in the number of engineering graduates\n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    "print(summarizer(text, max_new_tokens=128, min_length=60, do_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a42733",
   "metadata": {},
   "source": [
    "#### 2. 감성 분석 모델의 기본 결과와  제로샷 요청 후 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f09046d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c685c8955c4fb2b315a83c6a94b708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519d9080e1844a82a46fd7ab6deda252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae95406f0b9d4c0eb451f29ce709f19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d626c4eeda1a45d4948838a4fdb1fcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "cache_dir = r\"D:\\WorkSpace\\Hands_on_Gen_AI\"\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, cache_dir=cache_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7abcafc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 4.4724, -3.6547]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer(\n",
    "    \"This movie was terrible!\", truncation=True, return_tensors=\"pt\"\n",
    ").input_ids\n",
    "classifier_output = model(input_ids)\n",
    "classifier_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80d6c04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_id = classifier_output.logits.argmax().item()\n",
    "predicted_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "abaf6dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "32fcc0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEGATIVE'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_with_classifier(sample):\n",
    "    \"\"\"Given a review, predict whether it is positive or negative\"\"\"\n",
    "    input_ids = tokenizer(\n",
    "        sample[\"text\"], truncation=True, return_tensors=\"pt\"\n",
    "    ).input_ids\n",
    "    classifier_output = model(input_ids)\n",
    "    sample[\"pred\"] = classifier_output.logits.argmax().item()\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "386eb047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'This movie was terrible!', 'pred': 0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_with_classifier({\"text\": \"This movie was terrible!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b954b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b003ba96a443bc82c2be707da045eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa47c1d691e24e72ac146ca28977f515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316174d0b0e64cbbab1d8204c194819c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4819b9b4be874b0c83b686727c4116cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2241ef2b44bd4e35b9f7eac24d58c548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8c718eae8a41cca6bcb30218fed8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ca95ccb5ba4501aadde78ea355579f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'pred'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "dataset = load_dataset(\"imdb\", cache_dir=cache_dir)[\"train\"]\n",
    "\n",
    "shuffled_dataset = dataset.shuffle(seed=42)\n",
    "small_dataset = shuffled_dataset.select(range(1000))\n",
    "\n",
    "updated_dataset = small_dataset.map(score_with_classifier)\n",
    "updated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "66f45366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix': array([[474,  38],\n",
       "        [ 81, 407]], dtype=int64)}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = evaluate.load(\"confusion_matrix\", cache_dir=cache_dir)\n",
    "cm = confusion_matrix.compute(\n",
    "    references=updated_dataset[\"label\"],\n",
    "    predictions=updated_dataset[\"pred\"],\n",
    ")\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db165dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm[\"confusion_matrix\"],\n",
    "    display_labels=[\"negative\", \"positive\"],\n",
    ")\n",
    "disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "\n",
    "plt.title(\"Normalized confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83dde5",
   "metadata": {},
   "source": [
    "#### 3. 의미 기반 검색 : FAQ 시스템을 만들어 보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d9bdcac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c932d701fe12446bb242a0f73a2c9a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a651a4e469498297c95494032465f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e162c91d36044ab7a69424c0286f28ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fcc9e3f87a4f17a63533edfb16dbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d48f3f2b5d64aa98328b48db720c1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8740918f6c438cb279bfb1fd9de5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde9bd11f09e4e97b393f11a8925d9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675b46a7d2b348a2953c83fe3a5065b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c114ea6b43234ff3bbf0f640e48262e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0963c757c2fb49bdb56d541db131c83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e596dbe26a16440ca3485df6b4a5e583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6003]], device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sentences = [\"I'm happy\", \"I'm full of happiness\"]\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", cache_folder=cache_dir)\n",
    "\n",
    "# Compute embedding for both lists\n",
    "embedding_1 = model.encode(sentences[0], convert_to_tensor=True)\n",
    "embedding_2 = model.encode(sentences[1], convert_to_tensor=True)\n",
    "\n",
    "util.pytorch_cos_sim(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1d228f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from https://faq.ssa.gov/en-US/topic/?id=CAT-01092\n",
    "\n",
    "faq = {\n",
    "    \"How do I get a replacement Medicare card?\": \"If your Medicare card was lost, stolen, or destroyed, you can request a replacement online at Medicare.gov.\",\n",
    "    \"How do I sign up for Medicare?\": \"If you already get Social Security benefits, you do not need to sign up for Medicare. We will automatically enroll you in Original Medicare (Part A and Part B) when you become eligible. We will mail you the information a few months before you become eligible.\",\n",
    "    \"What are Medicare late enrollment penalties?\": \"In most cases, if you don’t sign up for Medicare when you’re first eligible, you may have to pay a higher monthly premium. Find more information at https://faq.ssa.gov/en-us/Topic/article/KA-02995\",\n",
    "    \"Will my Medicare premiums be higher because of my higher income?\": \"Some people with higher income may pay a larger percentage of their monthly Medicare Part B and prescription drug costs based on their income. We call the additional amount the income-related monthly adjustment amount.\",\n",
    "    \"What is Medicare and who can get it?\": \"Medicare is a health insurance program for people age 65 or older. Some younger people are eligible for Medicare including people with disabilities, permanent kidney failure and amyotrophic lateral sclerosis (Lou Gehrig’s disease or ALS). Medicare helps with the cost of health care, but it does not cover all medical expenses or the cost of most long-term care.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e0493e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 384])\n"
     ]
    }
   ],
   "source": [
    "corpus_embeddings = model.encode(list(faq.values()), convert_to_tensor=True)\n",
    "print(corpus_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eba9219c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question = \"Do I need to pay more after a raise?\"\n",
    "query_embedding = model.encode(user_question, convert_to_tensor=True)\n",
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cbedbd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 question (p=0.357962965965271): Will my Medicare premiums be higher because of my higher income?\n",
      "Answer: Some people with higher income may pay a larger percentage of their monthly Medicare Part B and prescription drug costs based on their income. We call the additional amount the income-related monthly adjustment amount.\n",
      "Top 2 question (p=0.27877578139305115): What are Medicare late enrollment penalties?\n",
      "Answer: In most cases, if you don’t sign up for Medicare when you’re first eligible, you may have to pay a higher monthly premium. Find more information at https://faq.ssa.gov/en-us/Topic/article/KA-02995\n",
      "Top 3 question (p=0.15840469300746918): How do I sign up for Medicare?\n",
      "Answer: If you already get Social Security benefits, you do not need to sign up for Medicare. We will automatically enroll you in Original Medicare (Part A and Part B) when you become eligible. We will mail you the information a few months before you become eligible.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "similarities = -util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "top_3 = similarities.cpu().argsort()[:3]\n",
    "for i, top_n in enumerate(top_3):\n",
    "    print(\n",
    "        f\"Top {i+1} question (p={-similarities[top_n]}): {list(faq.keys())[top_n]}\"\n",
    "    )\n",
    "    print(f\"Answer: {list(faq.values())[top_n]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "af7a9193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 question (p=0.357962965965271): Will my Medicare premiums be higher because of my higher income?\n",
      "Answer: Some people with higher income may pay a larger percentage of their monthly Medicare Part B and prescription drug costs based on their income. We call the additional amount the income-related monthly adjustment amount.\n",
      "Top 2 question (p=0.27877578139305115): What are Medicare late enrollment penalties?\n",
      "Answer: In most cases, if you don’t sign up for Medicare when you’re first eligible, you may have to pay a higher monthly premium. Find more information at https://faq.ssa.gov/en-us/Topic/article/KA-02995\n",
      "Top 3 question (p=0.15840469300746918): How do I sign up for Medicare?\n",
      "Answer: If you already get Social Security benefits, you do not need to sign up for Medicare. We will automatically enroll you in Original Medicare (Part A and Part B) when you become eligible. We will mail you the information a few months before you become eligible.\n"
     ]
    }
   ],
   "source": [
    "similarities = util.semantic_search(\n",
    "    query_embedding, corpus_embeddings, top_k=3\n",
    ")[0]\n",
    "for i, result in enumerate(similarities):\n",
    "    corpus_id = result[\"corpus_id\"]\n",
    "    score = result[\"score\"]\n",
    "    print(f\"Top {i+1} question (p={score}): {list(faq.keys())[corpus_id]}\")\n",
    "    print(f\"Answer: {list(faq.values())[corpus_id]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdxl_env_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
